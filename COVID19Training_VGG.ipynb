{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID19Training_VGG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachitgithub/Covid-Detection/blob/main/COVID19Training_VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gyKOi8EPITT"
      },
      "source": [
        "# **Install TensorFlow GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UboFrn87qNVe",
        "outputId": "2756e1d6-0aa9-428f-d83f-5088d72d256d"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLc0x1XRPPVm"
      },
      "source": [
        "# **Import GDRIVE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SXklTJgqQyV",
        "outputId": "627bf40e-86b8-49e6-c5a2-d526abb45b16"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M55jhmwBPTGp"
      },
      "source": [
        "# **Import Tensor Flow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPOllQPgqUky",
        "outputId": "00fb494b-efe6-4fa1-fbc4-4e535ed7cd85"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3UaO-sPXkz"
      },
      "source": [
        "# **Import Keras Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6d6JctTqdW2"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.layers import Activation,Dense,Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import accuracy_score,roc_curve,confusion_matrix,precision_score,recall_score,f1_score,roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt_False_Positive_vs_True_Positive\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoGghyDrPcMl"
      },
      "source": [
        "# **Build VGG CNN Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHfmSsyapGlw"
      },
      "source": [
        "def Build_CNN_Model():\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    #                        VGG Model \n",
        "    # -------------------------------------------------------------------------\n",
        "    # load VGG model\n",
        "    vgg = VGG19(include_top=True, input_shape=(224, 224, 3))\n",
        "\n",
        "    # mark loaded layers as trainable\n",
        "    for layer in vgg.layers:\n",
        "\t    layer.trainable = True      \n",
        "\t\n",
        "  \n",
        "    #  Flatten and Fully Connected Layer\n",
        "    Flat_layer = Flatten()(vgg.layers[11].output)\n",
        "\n",
        "    FC_layer = Dense(100)(Flat_layer)    \n",
        "       \n",
        "    Act_layer = Activation('relu')(FC_layer)\n",
        "    \n",
        "    #  Softmax Classifier\n",
        "    Class_layer = Dense(2)(Act_layer)\n",
        "    \n",
        "    Softmax_layer = Activation('softmax')(Class_layer)\n",
        "        \n",
        "\t# define new model    \n",
        "    model = Model(inputs=vgg.inputs, outputs=Softmax_layer)\n",
        "            \n",
        "    #  Display model\n",
        "    model.summary()\n",
        "    \n",
        "\t# compile model\n",
        "\n",
        "    opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeLn5RJZPnKl"
      },
      "source": [
        "# **Train VGG CNN Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT6jo0OmquCL"
      },
      "source": [
        "# train and evalluate cnn model\n",
        "def Train_CNN_Model(model):\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    #                        Train CNN Model \n",
        "    # -------------------------------------------------------------------------\n",
        "    \n",
        "    # create data generators    \n",
        "    # create data generators    \n",
        "    # create data generators    \n",
        "    train_datagen = ImageDataGenerator(\n",
        "                                     rescale=1.0/255.0,\n",
        "                                     featurewise_center= True,\n",
        "                                     featurewise_std_normalization = True,\n",
        "                                     rotation_range=10,\n",
        "                                     width_shift_range=0.1,\n",
        "                                     height_shift_range=0.1,\n",
        "                                     zoom_range=0.2,                                     \n",
        "                                     brightness_range=[0.2,1.0],\n",
        "                                     )\n",
        "    valid_datagen = ImageDataGenerator(\n",
        "                                     rescale=1.0/255.0,\n",
        "                                     featurewise_center= True,\n",
        "                                     featurewise_std_normalization = True)\n",
        "    \n",
        "   \n",
        "   \n",
        "    # prepare iterators\n",
        "    batch_size=32\n",
        "    train_it = train_datagen.flow_from_directory('/content/drive/MyDrive/COVID-19-Deep-Learning-Project-Colab/Dataset/train/',classes =('Normal','Covid'),batch_size=batch_size, target_size=(224, 224))\n",
        "    valid_it = valid_datagen.flow_from_directory('/content/drive/MyDrive/COVID-19-Deep-Learning-Project-Colab/Dataset/val/',classes =('Normal','Covid'),batch_size=batch_size, target_size=(224, 224))\n",
        "\n",
        "\n",
        "    epochs=100;\n",
        "    \n",
        "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=valid_it, validation_steps=len(valid_it), epochs=epochs, verbose=1)\n",
        "   \n",
        "    \n",
        "    #  \"Accuracy\"\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    # \"Loss\"\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\t# save model\n",
        "    model.save('/content/drive/MyDrive/COVID-19-Deep-Learning-Project-Colab/saved_models/CoVID19-VGG_cnn_model.h5')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akk2CJw7Pp6O"
      },
      "source": [
        "# **Evaluate Inception CNN Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eW1T2Ekq5MM"
      },
      "source": [
        "def Evaluate_CNN_Model():\n",
        "    # -------------------------------------------------------------------------\n",
        "    #                        Evaluate CNN Model \n",
        "    # -------------------------------------------------------------------------\n",
        "    \n",
        "    # load model\n",
        "    model = load_model('/content/drive/MyDrive/COVID-19-Deep-Learning-Project-Colab/saved_models/CoVID19-VGG_cnn_model.h5')\n",
        "\n",
        "    \n",
        "       # load test data\n",
        "    batch_size=32\n",
        "    test_datagen = ImageDataGenerator(\n",
        "                                     rescale=1.0/255.0,\n",
        "                                     featurewise_center= True,\n",
        "                                     featurewise_std_normalization = True)\n",
        "    \n",
        "    test_it = test_datagen.flow_from_directory('Data/test/',classes =('normal','abnormal'), \n",
        "                                               shuffle=False,batch_size=batch_size, target_size=(224, 224))\n",
        "    \n",
        "    y_true = test_it.classes;\n",
        "\n",
        "    y_pred = model.predict_generator(test_it, steps=len(test_it), verbose=1)\n",
        "\n",
        "    \n",
        "    y_pred_prob = y_pred[:,1]\n",
        "\n",
        "     \n",
        "    y_pred_binary =  y_pred_prob > 0.5\n",
        "   \n",
        "    #Confution Matrix    \n",
        "    print('\\nConfusion Matrix\\n -------------------------')    \n",
        "    print(confusion_matrix(y_true,y_pred_binary));\n",
        "    \n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "    \n",
        "    \n",
        "    # precision tp / (tp + fp)\n",
        "    precision = precision_score(y_true, y_pred_binary)\n",
        "    print('Precision: %f' % precision)\n",
        "    \n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = recall_score(y_true, y_pred_binary)\n",
        "    print('Recall: %f' % recall)\n",
        "    \n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_score(y_true, y_pred_binary)\n",
        "    print('F1 score: %f' % f1)    \n",
        "       \n",
        "    # ROC AUC\n",
        "    auc = roc_auc_score(y_true, y_pred_prob)\n",
        "    print('ROC AUC: %f' % auc)\n",
        "    \n",
        "    \n",
        "    # calculate roc curves\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
        "        \n",
        "    # plot the roc curve for the model\n",
        "    plt.figure()\n",
        "    plt_False_Positive_vs_True_Positive.plot(fpr, tpr, linestyle='--', label='')\n",
        "    \n",
        "    # axis labels\n",
        "    plt_False_Positive_vs_True_Positive.xlabel('False Positive Rate')\n",
        "    plt_False_Positive_vs_True_Positive.ylabel('True Positive Rate')\n",
        "       \n",
        "    # show the legend\n",
        "    plt_False_Positive_vs_True_Positive.legend()\n",
        "    # show the plot\n",
        "    plt_False_Positive_vs_True_Positive.show()\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqwwYBQsqysR",
        "outputId": "a3d5b85d-74c3-436e-c7fa-1bb5d428abea"
      },
      "source": [
        "# main entry\n",
        "    \n",
        "model = Build_CNN_Model()\n",
        "\n",
        "Train_CNN_Model(model)\n",
        "    \n",
        "Evaluate_CNN_Model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 3s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 200704)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               20070500  \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 22,396,270\n",
            "Trainable params: 22,396,270\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Found 1463 images belonging to 2 classes.\n",
            "Found 365 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From <ipython-input-7-9b2e2f1693e7>:37: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 2/46 [>.............................] - ETA: 6s - loss: 3709.0122 - accuracy: 0.4531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0864s vs `on_train_batch_end` time: 0.2197s). Check your callbacks.\n",
            "46/46 [==============================] - 371s 8s/step - loss: 168.8983 - accuracy: 0.4990 - val_loss: 0.6360 - val_accuracy: 0.9205\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6782 - accuracy: 0.5680 - val_loss: 0.6849 - val_accuracy: 0.4932\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6508 - accuracy: 0.5899 - val_loss: 0.6649 - val_accuracy: 0.4932\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6070 - accuracy: 0.6555 - val_loss: 0.4348 - val_accuracy: 0.8493\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6700 - accuracy: 0.5373 - val_loss: 0.6929 - val_accuracy: 0.5068\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6929 - accuracy: 0.5079 - val_loss: 0.6923 - val_accuracy: 0.5068\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6924 - accuracy: 0.5079 - val_loss: 0.6907 - val_accuracy: 0.5068\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6895 - accuracy: 0.5455 - val_loss: 0.6672 - val_accuracy: 0.4959\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 67s 1s/step - loss: 0.6742 - accuracy: 0.6418 - val_loss: 0.6011 - val_accuracy: 0.6438\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6724 - accuracy: 0.5789 - val_loss: 0.6842 - val_accuracy: 0.5068\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6892 - accuracy: 0.5079 - val_loss: 0.6793 - val_accuracy: 0.5068\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6961 - accuracy: 0.5407 - val_loss: 0.6486 - val_accuracy: 0.6466\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.6598 - accuracy: 0.6323 - val_loss: 0.5146 - val_accuracy: 0.7562\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.5813 - accuracy: 0.7088 - val_loss: 0.4202 - val_accuracy: 0.8082\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 68s 1s/step - loss: 0.5116 - accuracy: 0.7621 - val_loss: 0.3038 - val_accuracy: 0.8849\n",
            "Epoch 16/100\n",
            " 2/46 [>.............................] - ETA: 30s - loss: 0.5730 - accuracy: 0.7500"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}